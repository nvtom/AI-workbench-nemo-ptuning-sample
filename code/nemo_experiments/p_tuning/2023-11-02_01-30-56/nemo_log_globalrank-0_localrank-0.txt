[NeMo I 2023-11-02 01:30:56 exp_manager:374] Experiments will be logged at /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56
[NeMo I 2023-11-02 01:30:56 exp_manager:797] TensorboardLogger has been set up
[NeMo I 2023-11-02 01:31:08 megatron_init:234] Rank 0 has data parallel group: [0]
[NeMo I 2023-11-02 01:31:08 megatron_init:237] All data parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:08 megatron_init:238] Ranks 0 has data parallel rank: 0
[NeMo I 2023-11-02 01:31:08 megatron_init:246] Rank 0 has model parallel group: [0]
[NeMo I 2023-11-02 01:31:08 megatron_init:247] All model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:08 megatron_init:257] Rank 0 has tensor model parallel group: [0]
[NeMo I 2023-11-02 01:31:08 megatron_init:261] All tensor model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:08 megatron_init:262] Rank 0 has tensor model parallel rank: 0
[NeMo I 2023-11-02 01:31:08 megatron_init:276] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2023-11-02 01:31:08 megatron_init:288] Rank 0 has embedding group: [0]
[NeMo I 2023-11-02 01:31:08 megatron_init:294] All pipeline model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:08 megatron_init:295] Rank 0 has pipeline model parallel rank 0
[NeMo I 2023-11-02 01:31:08 megatron_init:296] All embedding group ranks: [[0]]
[NeMo I 2023-11-02 01:31:08 megatron_init:297] Rank 0 has embedding rank: 0
[NeMo I 2023-11-02 01:31:09 megatron_init:234] Rank 0 has data parallel group: [0]
[NeMo I 2023-11-02 01:31:09 megatron_init:237] All data parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:09 megatron_init:238] Ranks 0 has data parallel rank: 0
[NeMo I 2023-11-02 01:31:09 megatron_init:246] Rank 0 has model parallel group: [0]
[NeMo I 2023-11-02 01:31:09 megatron_init:247] All model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:09 megatron_init:257] Rank 0 has tensor model parallel group: [0]
[NeMo I 2023-11-02 01:31:09 megatron_init:261] All tensor model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:09 megatron_init:262] Rank 0 has tensor model parallel rank: 0
[NeMo I 2023-11-02 01:31:09 megatron_init:276] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2023-11-02 01:31:09 megatron_init:288] Rank 0 has embedding group: [0]
[NeMo I 2023-11-02 01:31:09 megatron_init:294] All pipeline model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:09 megatron_init:295] Rank 0 has pipeline model parallel rank 0
[NeMo I 2023-11-02 01:31:09 megatron_init:296] All embedding group ranks: [[0]]
[NeMo I 2023-11-02 01:31:09 megatron_init:297] Rank 0 has embedding rank: 0
[NeMo W 2023-11-02 01:31:09 modelPT:244] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2023-11-02 01:31:09 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpdxji4ao5/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpdxji4ao5/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt
[NeMo I 2023-11-02 01:31:09 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpdxji4ao5/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpdxji4ao5/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False
[NeMo I 2023-11-02 01:31:11 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.
[NeMo I 2023-11-02 01:31:12 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /mnt/ngc/megatron_gpt_345m.nemo.
[NeMo I 2023-11-02 01:31:12 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.
[NeMo I 2023-11-02 01:31:13 megatron_init:234] Rank 0 has data parallel group: [0]
[NeMo I 2023-11-02 01:31:13 megatron_init:237] All data parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:13 megatron_init:238] Ranks 0 has data parallel rank: 0
[NeMo I 2023-11-02 01:31:13 megatron_init:246] Rank 0 has model parallel group: [0]
[NeMo I 2023-11-02 01:31:13 megatron_init:247] All model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:13 megatron_init:257] Rank 0 has tensor model parallel group: [0]
[NeMo I 2023-11-02 01:31:13 megatron_init:261] All tensor model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:13 megatron_init:262] Rank 0 has tensor model parallel rank: 0
[NeMo I 2023-11-02 01:31:13 megatron_init:276] Rank 0 has pipeline model parallel group: [0]
[NeMo I 2023-11-02 01:31:13 megatron_init:288] Rank 0 has embedding group: [0]
[NeMo I 2023-11-02 01:31:13 megatron_init:294] All pipeline model parallel group ranks: [[0]]
[NeMo I 2023-11-02 01:31:13 megatron_init:295] Rank 0 has pipeline model parallel rank 0
[NeMo I 2023-11-02 01:31:13 megatron_init:296] All embedding group ranks: [[0]]
[NeMo I 2023-11-02 01:31:13 megatron_init:297] Rank 0 has embedding rank: 0
[NeMo W 2023-11-02 01:31:13 modelPT:244] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.
[NeMo I 2023-11-02 01:31:13 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: /tmp/tmpcacxj0hd/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, and merges file: /tmp/tmpcacxj0hd/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt
[NeMo I 2023-11-02 01:31:13 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /tmp/tmpcacxj0hd/bfcdca5e44814366bdb5dcd651325152_gpt2-vocab.json, merges_files: /tmp/tmpcacxj0hd/315a11fd68be49d6abdb34363e8c4997_gpt2-merge.txt, special_tokens_dict: {}, and use_fast: False
[NeMo I 2023-11-02 01:31:14 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.
[NeMo I 2023-11-02 01:31:14 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /mnt/ngc/megatron_gpt_345m.nemo.
[NeMo I 2023-11-02 01:31:14 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.
[NeMo W 2023-11-02 01:31:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `MegatronGPTPromptLearningModel.on_train_batch_start` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.
      rank_zero_warn(
    
[NeMo W 2023-11-02 01:31:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/configuration_validator.py:175: UserWarning: The `batch_idx` argument in `MegatronGPTPromptLearningModel.on_train_batch_end` hook may not match with the actual batch index when using a `dataloader_iter` argument in your `training_step`.
      rank_zero_warn(
    
[NeMo W 2023-11-02 01:31:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/lightning_fabric/plugins/environments/torchelastic.py:36: UserWarning: MASTER_ADDR environment variable is not defined. Set as localhost
      rank_zero_warn("MASTER_ADDR environment variable is not defined. Set as localhost")
    
[NeMo W 2023-11-02 01:31:22 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/lightning_fabric/plugins/environments/torchelastic.py:44: UserWarning: MASTER_PORT environment variable is not defined. Set as 12910
      rank_zero_warn("MASTER_PORT environment variable is not defined. Set as 12910")
    
[NeMo I 2023-11-02 01:31:23 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... 
[NeMo I 2023-11-02 01:31:25 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation
[NeMo I 2023-11-02 01:31:25 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... 
[NeMo I 2023-11-02 01:31:26 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation
[NeMo I 2023-11-02 01:31:26 nlp_overrides:124] Configuring DDP for model parallelism.
[NeMo W 2023-11-02 01:31:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:82.)
      self._dummy_overflow_buf = torch.cuda.IntTensor([0])
    
[NeMo I 2023-11-02 01:31:26 modelPT:721] Optimizer config = FusedAdam (
    Parameter Group 0
        betas: [0.9, 0.98]
        bias_correction: True
        eps: 1e-08
        lr: 0.0001
        weight_decay: 0.01
    )
[NeMo I 2023-11-02 01:31:26 lr_scheduler:910] Scheduler "<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f371c22d2d0>" 
    will be used during training (effective maximum steps = 4000) - 
    Parameters : 
    (warmup_steps: 50
    min_lr: 0.0
    constant_steps: 0
    max_steps: 4000
    )
[NeMo W 2023-11-02 01:31:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:401: UserWarning: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.
      rank_zero_warn(
    
[NeMo W 2023-11-02 01:31:26 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest
      warnings.warn("This function is only for unittest")
    
[NeMo I 2023-11-02 01:31:29 megatron_gpt_prompt_learning_model:440] val_loss: 8.539896011352539
[NeMo W 2023-11-02 01:31:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
      warning_cache.warn(
    
[NeMo W 2023-11-02 01:31:29 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:344: UserWarning: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.
      rank_zero_warn(
    
[NeMo W 2023-11-02 01:31:32 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.
      warning_cache.warn(
    
[NeMo W 2023-11-02 01:31:32 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
      warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
    
[NeMo I 2023-11-02 01:35:36 megatron_gpt_prompt_learning_model:440] val_loss: 0.6329265236854553
[NeMo I 2023-11-02 01:35:36 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
[NeMo I 2023-11-02 01:40:05 megatron_gpt_prompt_learning_model:440] val_loss: 0.6318104267120361
[NeMo I 2023-11-02 01:40:05 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
[NeMo I 2023-11-02 01:40:05 nlp_overrides:231] Removing checkpoint: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/megatron_gpt_prompt_tune--val_loss=0.633-step=1000-last.ckpt
[NeMo I 2023-11-02 01:44:34 megatron_gpt_prompt_learning_model:440] val_loss: 0.6326885223388672
[NeMo I 2023-11-02 01:44:35 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
[NeMo I 2023-11-02 01:44:35 nlp_overrides:231] Removing checkpoint: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/megatron_gpt_prompt_tune--val_loss=0.633-step=1000.ckpt
[NeMo I 2023-11-02 01:44:35 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
[NeMo I 2023-11-02 01:44:35 nlp_overrides:231] Removing checkpoint: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/megatron_gpt_prompt_tune--val_loss=0.632-step=2000-last.ckpt
[NeMo I 2023-11-02 01:49:12 megatron_gpt_prompt_learning_model:440] val_loss: 0.61149001121521
[NeMo I 2023-11-02 01:49:13 nlp_overrides:231] Removing checkpoint: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/megatron_gpt_prompt_tune--val_loss=0.633-step=3000.ckpt
[NeMo I 2023-11-02 01:49:13 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
[NeMo I 2023-11-02 01:49:13 nlp_overrides:231] Removing checkpoint: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/megatron_gpt_prompt_tune--val_loss=0.633-step=3000-last.ckpt
[NeMo I 2023-11-02 01:49:13 nemo_model_checkpoint:168] New best .nemo model saved to: /project/code/nemo_experiments/p_tuning/2023-11-02_01-30-56/checkpoints/p_tuning.nemo
